#!/usr/bin/env python
# coding: utf-8

# # Проект №9: Временные ряды

# **Описание проекта:**
# 
# Компания «Чётенькое такси» собрала исторические данные о заказах такси в аэропортах. Чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час. 
# 
# **Цель проекта:** Построить модель для прогнозирования заказов такси на следующий час.

# **Инструкция по выполнению проекта:**
# 1. Загрузите данные и выполните их ресемплирование по одному часу.
# 2. Проанализируйте данные.
# 3. Обучите разные модели с различными гиперпараметрами. Сделайте тестовую выборку размером 10% от исходных данных.
# 4. Проверьте данные на тестовой выборке и сделайте выводы.
# 
# **Примечание:** Значение метрики RMSE на тестовой выборке должно быть не больше 48.

# **Описание данных:**
# 
# Данные лежат в файле 'taxi.csv'.  Количество заказов находится в столбце 'num_orders' (от англ. number of orders, «число заказов»).

# **План работы с проектом:**
# 1. Загрузка и подготовка данных;
# 2. Анализ данных;
# 3. Обучение моделей;
# 4. Тестирование моделей;
# 5. Формирование итоговых выводов.

# ## 1. Загрузка и подготовка данных

# In[1]:


# загрузим стандартные библиотеки, необходимые для работы
import pandas as pd
import math
import sklearn
import numpy as np
from scipy import stats as st

# загрузим библиотеки для визуализации данных
import matplotlib.pyplot as plt 
import seaborn as sns

# загрузим модули для работыы над конкретной задачей
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, make_scorer
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from catboost import CatBoostRegressor
import lightgbm as lgb
import time

import warnings
warnings.filterwarnings("ignore")

# зададим константу
RANDOM_STATE = 42


# In[2]:


# загрузим данные и посмотрим общую информацию о них
try:
    # локальный путь к файлу
    taxi = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ПФ/Временные_ряды/taxi.csv')
except:
    # путь к файлу в тренажере
    taxi = pd.read_csv('/datasets/taxi.csv')

# посмотрим первые 5 строк датафрема
taxi.head()


# In[3]:


# посмотрим общую информацию о таблице
taxi.info()


# **Примечание:** При первичном осмотре данных видно, значения в столбцах соответствуют описанию задачи, что пропуски отсутствуют. Тип данных в столбце 'datetime' определ неверно, необходимо заменить. Также сразу заменим индексы на значения столбца 'datetime'.

# In[4]:


# загрузим данные и посмотрим общую информацию о них
try:
    # локальный путь к файлу
    taxi = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ПФ/Временные_ряды/taxi.csv', index_col='datetime', parse_dates=[0])
except:
    # путь к файлу в тренажере
    taxi = pd.read_csv('/datasets/taxi.csv', index_col='datetime', parse_dates=[0])

# посмотрим первые 5 строк датафрема
taxi.head()


# In[5]:


# посмотрим общую информацию о таблице
taxi.info()


# In[6]:


# посмотрим, расположены ли данные в хронологическом порядке (монотонно возрастают)
taxi.index.is_monotonic_increasing


# In[7]:


# проведем сортировку индексов в таблице (на всякий случай)
taxi = taxi.sort_index()


# In[8]:


# проведем ресемплирование данных по одному часу
# т.к. предсказываем кол-во заказов такси на следующий час, то возьмем агрегирующую функцию - сумму
taxi = taxi.resample('1H').sum()


# In[9]:


# посмотрим получившийся временной промежуток
print(f'Временной промежуток данных: {taxi.index.min()} - {taxi.index.max()}')


# **Обобщающий вывод этапа "Загрузка и подготовка данных":**
# 1. Данные соответствуют описанию задачи, пропуски отсутствуют.
# 2. Изменен тип данных в столбце 'datetime'.
# 3. Индексы заменены на значения столбца 'datetime.
# 4. Даты расположены в хронологическом порядке и просемплированы по одному часу (по условию задачи).

# ## 2. Анализ данных

# Для начала посмотрим различные характеристикивременного ряда за весь период с марта по август 2018 года.

# In[10]:


decomposed = seasonal_decompose(taxi)

plt.figure(figsize=(10, 10))

plt.subplot(311)
decomposed.trend.plot(ax=plt.gca())
plt.title('Trend')

plt.subplot(312)
decomposed.seasonal.plot(ax=plt.gca())
plt.title('Seasonality')

plt.subplot(313)
decomposed.resid.plot(ax=plt.gca())
plt.title('Residuals')
plt.tight_layout()


# **Примечание:** 
# 1. График тренда имеет восходящий характер, указывающий на увеличение количества заказов по месяцам, но в то же время видны различные спады и всплески, которые уже могут быть связаны с неделями и определенными днями недели. Наблюдаетмя наличие некоторого шума в линии тренда.
# 2. график сезонности показывает взаимосвязь по неделям, т.к. присутствует некоторое количество повторяющихся элементов графика.
# 3. Заметны небольшие признаки нестационарности временного ряда, т.к. со временем присутствуют изменения среднего значения.

# Посмотрим различные характеристики временного ряда за последний месяц временного промежутка данных (август 2018 года), а именно: тренд, сезонную составляющую и остаток декомпозиции.

# In[11]:


decomposed = seasonal_decompose(taxi['2018-08':'2018-08'])

plt.figure(figsize=(10, 10))

plt.subplot(311)
decomposed.trend.plot(ax=plt.gca())
plt.title('Trend')

plt.subplot(312)
decomposed.seasonal.plot(ax=plt.gca())
plt.title('Seasonality')

plt.subplot(313)
decomposed.resid.plot(ax=plt.gca())
plt.title('Residuals')
plt.tight_layout()


# **Обобщающий вывод этапа "Анализ данных":**
# 1. График тренда за последний месяц (август 2018 года) показывает постепенное увеличение количества заказав с начала к концу месяца. Также можно увидеть некоторые спады за этот промежуток каждые 7 дней. Можно сделать предположение о том, что на выходных (в воскресенье) количество заказов такси падало, а к понедельнику снова значительно возрастало.
# 2. График сезонности за период суток на первый взгляд выглядит статичным в интервале суток.
# 3. График остатков на первый взгляд указывает на нестационарность временного ряда, т.к. среднее значение иногда изменяется в силу значительных всплесков, которые обусловлены изменением спроса на такси.

# ## 3. Обучение моделей

# ### 3.1 Создание новых признаков

# In[12]:


# напишем собственную функцию для создания новых признаков
def make_features(data, max_lag, rolling_mean_size):
    df = data.copy()
    df['hour'] = df.index.day
    df['dayofweek'] = df.index.dayofweek
    
    for lag in range(1, max_lag + 1):
        df['lag_{}'.format(lag)] = df['num_orders'].shift(lag)

    df['rolling_mean'] = df['num_orders'].shift().rolling(rolling_mean_size).mean()

    return df


# In[13]:


# создадим таблицу для обучения с новыми признаками
data = make_features(taxi, 30, 50)


# ### 3.2 Подготовка данных для обучения моделей

# In[14]:


# разделим данные на тестовую и тренировочные выборки в соотношении 9:1 (по условию задачи: 10% - тестовая выборка)
train, test = train_test_split(data, shuffle=False, test_size=0.1)

# удалим образовавшиеся пропуски
train = train.dropna()


# In[15]:


# посмотрим первые 5 строк получившейся тренировочной выборки
train.head()


# In[16]:


# выделем целевой и обычные признаки
X_train = train.drop(columns='num_orders')
y_train = train['num_orders']
X_test = test.drop(columns='num_orders')
y_test = test['num_orders']


# In[17]:


# создадим таблицу, в которую будем записывать все результаты для последующего анализа
results = pd.DataFrame(columns=['Среднее RMSE', 'Среднее время обучения (с)', 'Среднее время предсказания (с)'])


# In[18]:


# напишем собственную функцию для расчета времени обучения, предсказания и RMSE (с использованием кросс-валидации)
def record_cv(model, result_df, X, y, n_splits=5):
    model_name = model.__class__.__name__
    # инициализируем метод кросс-валидации для временных рядов
    tscv = TimeSeriesSplit(n_splits=n_splits)

    rmses = []
    fit_times = []
    pred_times = []
    
    # разделение данных с учетом кросс-валидации
    for train_idx, val_idx in tscv.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        # обучение модели и замер времени для этого
        start_fit = datetime.now()
        model.fit(X_train, y_train)
        end_fit = datetime.now()

        # предсказание модели и замер времени для этого
        start_pred = datetime.now()
        y_pred = model.predict(X_val)
        end_pred = datetime.now()

        # расчет метрики
        rmse = mean_squared_error(y_val, y_pred, squared=False)

        # сохранение результатов
        rmses.append(rmse)
        fit_times.append((end_fit - start_fit).total_seconds())
        pred_times.append((end_pred - start_pred).total_seconds())

    # запись всех результатов в окончательную таблицу
    result_df.loc[model_name] = [
        np.mean(rmses),
        np.mean(fit_times),
        np.mean(pred_times)
    ]

    # вывод информации о модели
    print(f'Модель {model_name}, Среднее RMSE = {np.mean(rmses):.4f}')
    
    return model


# ### 3.3 Модель LinearRegression

# In[19]:


# инициализируем модель
linear_model = LinearRegression()

# применим функцию
record_cv(linear_model, results, X_train, y_train)


# ### 3.4 Модель RandomForestRegressor

# In[20]:


# подберем наилучшие гиперпараметры для модели
# rfr_parameters = {'n_estimators': range(100, 251, 25),
                  # 'max_depth': range(10, 20, 2),
                  # 'random_state': [13],
                  # 'n_jobs': [-1]
                 # }


# In[21]:


# самостоятельно создадим метрику для оценки качества модели
# def RMSE(y_true, y_pred):
    # return (mean_squared_error(y_true, y_pred) ** 0.5)

# scorer_rmse = make_scorer(RMSE, greater_is_better=False)


# In[22]:


# инициализируем модель
# rfr_model = RandomForestRegressor()


# In[23]:


# %%time
# tscv = TimeSeriesSplit(n_splits=5)

# grid_rfr = GridSearchCV(rfr_model,
                        # rfr_parameters,
                        # scoring=scorer_rmse,
                        # cv=tscv.split(X_train))
# grid_rfr.fit(X_train, y_train)
# grid_rfr.best_params_


# **Примечание:** Был проведен подбор гиперпараметров для модели RandomForestRegressor(), но он производится около 30 минут, поэтому для ускорения запуска кода, часть с реализацией подбора была закомментирована. В дальнейшем гиперпараметры для моделей будут подбираться вручную.

# ![rfr_photo.jpg](attachment:22728340-f572-42c1-bbb8-4a1d49443bfb.jpg)

# In[24]:


# инициализируем модель с наилучшими параметрами (получены с помощью закомментированного кода (см. фото выше))
rfr_model_2 = RandomForestRegressor(max_depth=16, n_estimators=150, n_jobs=-1, random_state=13)

# применим функцию
record_cv(rfr_model_2, results, X_train, y_train)


# ### 3.5 Модель CatBoostRegressor

# In[25]:


# зададим параметры для модели вручную, чтобы не тратить много времени на поиск наилучших (исключительно в целях реализации проекта)
# инициализируем модель
cat_model = CatBoostRegressor(learning_rate=0.1, random_state=RANDOM_STATE, verbose=100)

# применим функцию
record_cv(cat_model, results, X_train, y_train)


# ### 3.6 Модель LightGBM

# In[26]:


# зададим параметры для модели вручную, чтобы не тратить много времени на поиск наилучших (исключительно в целях реализации проекта)
# инициализируем модель
lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE, n_jobs=-1)

# применим функцию
record_cv(lgb_model, results, X_train, y_train)


# **Обобщающий вывод этапа "Обучение моделей":**
# 1. Для обучения моделей с помощью собственной функции были созданы новые признаки.
# 2. Полученная для обучения моделей таблица была разбита на тренировочную и тестовую выборки.
# 3. С помощью кросс-валидации были обучены модели LinearRegression, RandomForestRegressor, CatBoostRegressor, LightCBM, а также рассчитаны время обучения и предсказания моделей и метрика оценки качества RMSE.

# ## 4. Тестирование моделей

# In[27]:


# посмотрим тпблицу, полученную после обучения всех моделей
results.sort_values(by='Среднее RMSE')


# **Примечание:** Лучшей моделью по метрике оценки качества RMSE оказалась CatBoostRegressor, однако, у нее достаточно долгое время обучения модели, следующие за ней две модели RandomForestRegressor и LGBMRegressor показали метрику оценки качества чуть ниже, чем у CatBoostRegressor, но с более быстрым временем обучения и предсказания. Так как по условию задачи стоит сделать акцент на оценку метрики качества RMSE, то для предсказания возьмем модель CatBoostRegressor.

# In[28]:


# выбираем лучшую модель
best_model = CatBoostRegressor(learning_rate=0.1, random_state=RANDOM_STATE, verbose=100)
best_model.fit(X_train, y_train)


# In[29]:


get_ipython().run_cell_magic('time', '', 'start_pred = time.time()\ny_pred = best_model.predict(X_test)\nend_pred = time.time() - start_pred\n')


# In[30]:


# расчет RMSE на тестовой выборке
rmse_test = mean_squared_error(y_test, y_pred, squared=False)

# вывод итоговых результатов
print(f"RMSE на тесте: {rmse_test:.4f}")
print(f"Время предсказания: {end_pred:.4f} секунд")


# **Примечание:** Полученная оценка метрики качества RMSE равна 42.6002, что полностью удобвлетворяет условию задачи: "Значение метрики RMSE на тестовой выборке должно быть не больше 48".

# In[31]:


# визуализируем полученные результаты
plt.figure(figsize=(20, 5))

plt.plot(y_test.index, y_test, label='Фактические значения')
plt.plot(y_test.index, y_pred, label='Предсказанные значения')

plt.title('Сравнение фактических и предсказанных значений')
plt.xlabel('Дата и время')
plt.ylabel('Число заказов')
plt.legend()
plt.tight_layout()
plt.show()


# **Обобщающий вывод этапа "Тестирование моделей":**
# 1. На данном этапе была выбрана лучшая модель поле обучения всех моделей, такой оказалась CatBoostRegressor, которая показала наилучшее значение метрики качества RMSE на кросс-валидации, равное 24.939416.
# 2. На основе лучшей модели было выполнено предсказание на тестовой выборке, которое показала значение метрики оценки качества, равное 42.6002, что полностью удобвлетворяет условию задачи: "Значение метрики RMSE на тестовой выборке должно быть не больше 48".
# 3. Проведена визуализация временного ряда по фактическим и предсказанным значениям.

# ## 5. Итоговые выводы

# В ходе работы были проанализированы данные, предоставленные компанией "Чётенькое такси", которая хочет разработать модель, позволяющую предсказывать количество заказов такси на следующий час.
# 
# Для реализации этой задачи было выполнено 4 этапа работы.
# 
# На **1 этапе: Загрузка и подготовка данных** были проанализированы все исходные данные и получены следующие результаты:
# 1. Данные соответствуют описанию задачи, пропуски отсутствуют.
# 2. Изменен тип данных в столбце 'datetime'.
# 3. Индексы заменены на значения столбца 'datetime.
# 4. Даты расположены в хронологическом порядке и просемплированы по одному часу (по условию задачи).
# 
# На **2 этапе: Анализ данных** были получены следующие результаты:
# 1. График тренда за последний месяц (август 2018 года) показывает постепенное увеличение количества заказав с начала к концу месяца. Также можно увидеть некоторые спады за этот промежуток каждые 7 дней. Можно сделать предположение о том, что на выходных (в воскресенье) количество заказов такси падало, а к понедельнику снова значительно возрастало.
# 2. График сезонности за период суток на первый взгляд выглядит статичным в интервале суток.
# 3. График остатков на первый взгляд указывает на нестационарность временного ряда, т.к. среднее значение иногда изменяется в силу значительных всплесков, которые обусловлены изменением спроса на такси.
# 
# На **3 этапе: Обучение моделей** было сделано:
# 1. Для обучения моделей с помощью собственной функции были созданы новые признаки.
# 2. Полученная для обучения моделей таблица была разбита на тренировочную и тестовую выборки.
# 3. С помощью кросс-валидации были обучены модели LinearRegression, RandomForestRegressor, CatBoostRegressor, LightCBM, а также рассчитаны время обучения и предсказания моделей и метрика оценки качества RMSE.
# 
# На **4 этапе: Тестирование моделей** было сделано:
# 1. На данном этапе была выбрана лучшая модель поле обучения всех моделей, такой оказалась CatBoostRegressor, которая показала наилучшее значение метрики качества RMSE на кросс-валидации, равное 24.939416.
# 2. На основе лучшей модели было выполнено предсказание на тестовой выборке, которое показала значение метрики оценки качества, равное 42.6002, что полностью удобвлетворяет условию задачи: "Значение метрики RMSE на тестовой выборке должно быть не больше 48".
# 3. Проведена визуализация временного ряда по фактическим и предсказанным значениям.
# 
# **Таким образом**, наилучшей моделью для предсказания количества заказов такси на следующий час является CatBoostRegressor с метрикой оценки качества на тестовой выборке, равной 42.6002, что полностью удобвлетворяет условию задачи: "Значение метрики RMSE на тестовой выборке должно быть не больше 48".
